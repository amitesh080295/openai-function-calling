{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling with OpenAI's GPT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import openai\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Vanilla Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"location\", \"unit\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What's the weather like in San Francisco?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `function_call=\"auto\"` will allow the model to choose whether or not it responds with a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-0613',\n",
    "    messages=[{'role': 'user', 'content': user_query}],\n",
    "    functions=function_descriptions,\n",
    "    function_call='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": \"{\\n  \\\"location\\\": \\\"San Francisco\\\",\\n  \\\"unit\\\": \\\"celsius\\\"\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ai_response_message = response['choices'][0]['message']\n",
    "print(ai_response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up user response\n",
    "user_location = ast.literal_eval(ai_response_message['function_call']['arguments']).get('location')\n",
    "user_unit = ast.literal_eval(ai_response_message['function_call']['arguments']).get('unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    weather_info = {\n",
    "        'location': location,\n",
    "        'temperature': '72',\n",
    "        'unit': unit,\n",
    "        'forecast': ['sunny', 'windy']\n",
    "    }\n",
    "\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_response = get_current_weather(\n",
    "    location=user_location,\n",
    "    unit=user_unit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"San Francisco, CA\", \"temperature\": \"72\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the response to our model for a natural language response\n",
    "\n",
    "second_response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo-0613',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': user_query},\n",
    "        ai_response_message,\n",
    "        {\n",
    "            'role': 'function',\n",
    "            'name': 'get_current_weather',\n",
    "            'content': function_response\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is sunny and windy with a temperature of 72Â°C.\n"
     ]
    }
   ],
   "source": [
    "print(second_response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Support For Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "from langchain.tools import format_tool_to_openai_function, MoveFileTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MoveFileTool()]\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'move_file',\n",
       "  'description': 'Move or rename a file from one location to another',\n",
       "  'parameters': {'title': 'FileMoveInput',\n",
       "   'description': 'Input for MoveFileTool.',\n",
       "   'type': 'object',\n",
       "   'properties': {'source_path': {'title': 'Source Path',\n",
       "     'description': 'Path of the file to move',\n",
       "     'type': 'string'},\n",
       "    'destination_path': {'title': 'Destination Path',\n",
       "     'description': 'New path for the moved file',\n",
       "     'type': 'string'}},\n",
       "   'required': ['source_path', 'destination_path']}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = llm.predict_messages([HumanMessage(content='move file foo to bar')], functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'move_file',\n",
       " 'arguments': '{\\n  \"source_path\": \"foo\",\\n  \"destination_path\": \"bar\"\\n}'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.additional_kwargs['function_call']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Financial Forecast Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"edit_financial_forecast\",\n",
    "                \"description\": \"Make an edit to a users financial forecast model\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"year\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The year the user would like to make an edit to their forecast for\",\n",
    "                        },\n",
    "                        \"category\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The category of the edit a user would like to edit\"\n",
    "                        },\n",
    "                        \"amount\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The amount of units the user would like to change\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"year\", \"category\", \"amount\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"print_financial_forecast\",\n",
    "                \"description\": \"Send the financial forecast to the printer\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"printer_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the name of the printer that the forecast should be sent to\",\n",
    "                            \"enum\": [\"home_printer\", \"office_printer\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"printer_name\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"\"\"\n",
    "Please do three things add 40 units to 2023 headcount\n",
    "and subtract 23 units from 2022 opex\n",
    "then print out the forecast at my home\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we are keeping track of the message history. As more support is added, we wouldn't need to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'edit_financial_forecast', 'arguments': '{\\n  \"year\": 2023,\\n  \"category\": \"headcount\",\\n  \"amount\": 40\\n}'}}, example=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response = llm.predict_messages([HumanMessage(content=user_request)],\n",
    "                                      functions=function_descriptions)\n",
    "first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'edit_financial_forecast',\n",
       "  'arguments': '{\\n  \"year\": 2023,\\n  \"category\": \"headcount\",\\n  \"amount\": 40\\n}'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_financial_forecast'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = first_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year: 2023      \n",
      "Category: headcount      \n",
      "Amount: 40      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the arguments that it gives us\n",
    "print(f\"\"\"\n",
    "Year: {ast.literal_eval(first_response.additional_kwargs['function_call']['arguments']).get('year')}      \n",
    "Category: {ast.literal_eval(first_response.additional_kwargs['function_call']['arguments']).get('category')}      \n",
    "Amount: {ast.literal_eval(first_response.additional_kwargs['function_call']['arguments']).get('amount')}      \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\'function_call\\': {\\'name\\': \\'edit_financial_forecast\\', \\'arguments\\': \\'{\\\\n  \"year\": 2022,\\\\n  \"category\": \"opex\",\\\\n  \"amount\": -23\\\\n}\\'}}\\nJust updated the financial forecast for year 2022, category opex and amount -23', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                        AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                        ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"Just updated the financial forecast for year 2023, category headcount amd amount 40\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)\n",
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'edit_financial_forecast',\n",
       "  'arguments': '{\\n  \"year\": 2022,\\n  \"category\": \"opex\",\\n  \"amount\": -23\\n}'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_financial_forecast'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = second_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'print_financial_forecast', 'arguments': '{\\n  \"printer_name\": \"home_printer\"\\n}'}}, example=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                       AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(second_response.additional_kwargs)),\n",
    "                                       ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"\"\"\n",
    "                                                        Just made the following updates: 2022, opex -23 and\n",
    "                                                        Year: 2023\n",
    "                                                        Category: headcount\n",
    "                                                        Amount: 40\n",
    "                                                    \"\"\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)\n",
    "third_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'print_financial_forecast',\n",
       "  'arguments': '{\\n  \"printer_name\": \"home_printer\"\\n}'}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print_financial_forecast'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = third_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I have added 40 units to the 2023 headcount and subtracted 23 units from the 2022 opex. The updated forecast has been printed at your home.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                       AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(second_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(third_response.additional_kwargs)),\n",
    "                                       ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"\"\"\n",
    "                                                        just printed the document at home\n",
    "                                                    \"\"\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)\n",
    "fourth_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have added 40 units to the 2023 headcount and subtracted 23 units from the 2022 opex. The updated forecast has been printed at your home.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
